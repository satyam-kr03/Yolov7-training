{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacebdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satyam/anaconda3/envs/yolo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from pytorch_accelerated.callbacks import (\n",
    "    EarlyStoppingCallback,\n",
    "    SaveBestModelCallback,\n",
    "    get_default_callbacks,\n",
    ")\n",
    "from pytorch_accelerated import Trainer\n",
    "from yolov7 import create_yolov7_model\n",
    "from yolov7.dataset import create_yolov7_transforms\n",
    "from yolov7.loss_factory import create_yolov7_loss\n",
    "from yolov7.trainer import (\n",
    "    Yolov7Trainer,\n",
    "    filter_eval_predictions,\n",
    ")\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "# === 1) Helper: run_inference using YOLOv7’s non_max_suppression ===\n",
    "def run_inference(\n",
    "    model,\n",
    "    image_path: str,\n",
    "    transforms,\n",
    "    filter_fn,\n",
    "    device: torch.device = None,\n",
    "    conf_threshold: float = 0.25,\n",
    "):\n",
    "    # 1) Prep\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # 2) Load + Transform\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_np = np.array(img)\n",
    "    tr_out = transforms(image=img_np, bboxes=[], labels=[])\n",
    "    img_t = tr_out[\"image\"]\n",
    "    if isinstance(img_t, np.ndarray):\n",
    "        x = torch.from_numpy(img_t).permute(2,0,1).float().unsqueeze(0)\n",
    "    else:\n",
    "        x = img_t.unsqueeze(0)\n",
    "    x = x.to(device)\n",
    "\n",
    "    # 3) Forward + model.postprocess → list of per-image detections\n",
    "    with torch.no_grad():\n",
    "        fpn_out = model(x)\n",
    "        # this returns List[Tensor] with shape [N,6]\n",
    "        preds = model.postprocess(fpn_out, conf_thres=conf_threshold)\n",
    "\n",
    "    # 4) Run the exact NMS callback you used in training\n",
    "    if filter_fn is not None:\n",
    "        preds = filter_fn(preds)  \n",
    "\n",
    "    # 5) Extract the first (and only) image’s detections\n",
    "    det = preds[0]  \n",
    "    if det is None or det.shape[0] == 0:\n",
    "        return img, torch.empty((0,4)), torch.empty((0,)), torch.empty((0,),dtype=torch.long)\n",
    "\n",
    "    boxes = det[:, :4].cpu()\n",
    "    scores = det[:, 4].cpu()\n",
    "    class_ids = det[:, 5].long().cpu()\n",
    "\n",
    "    return img, boxes, scores, class_ids\n",
    "\n",
    "# === 2) Rebuild trainer exactly as in training ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 1\n",
    "model = create_yolov7_model(\"yolov7\", num_classes=num_classes, pretrained=False)\n",
    "loss_func = create_yolov7_loss(model, image_size=416)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "callbacks = [\n",
    "    # you only need SaveBestModelCallback if that's what produced best_model.ckpt\n",
    "    SaveBestModelCallback(watch_metric=\"map\", greater_is_better=True),\n",
    "    EarlyStoppingCallback(early_stopping_patience=3, watch_metric=\"map\", greater_is_better=True),\n",
    "    *get_default_callbacks(progress_bar=False),\n",
    "]\n",
    "trainer = Yolov7Trainer(\n",
    "    model=model,\n",
    "    loss_func=loss_func,\n",
    "    optimizer=optimizer,\n",
    "    callbacks=callbacks,\n",
    "    filter_eval_predictions_fn=partial(filter_eval_predictions, confidence_threshold=0.01, nms_threshold=0.3),\n",
    ")\n",
    "\n",
    "# === 3) Load the checkpoint Chris’s callback saved ===\n",
    "ckpt = Path(\"/home/satyam/Dev/Yolov7-training/cars_model.pt\")  # or .pt\n",
    "trainer.load_checkpoint(ckpt, load_scheduler=False)\n",
    "\n",
    "# now trainer.get_model() is your fine-tuned YOLOv7\n",
    "ft_model = trainer.get_model()\n",
    "\n",
    "# === 4) Inference on a sample image ===\n",
    "infer_transforms = create_yolov7_transforms(training=False, image_size=(416,416))\n",
    "sample_image = \"/home/satyam/Dev/data/cars/testing_images/vid_5_400.jpg\"\n",
    "pil_img, boxes, scores, class_ids = run_inference(\n",
    "    ft_model,\n",
    "    sample_image,\n",
    "    transforms=infer_transforms,\n",
    "    filter_fn=partial(filter_eval_predictions, confidence_threshold=0.25, nms_threshold=0.3),\n",
    "    device=device,\n",
    "    conf_threshold=0.25,\n",
    ")\n",
    "\n",
    "# === 5) Draw & display ===\n",
    "draw = ImageDraw.Draw(pil_img)\n",
    "font = ImageFont.load_default()\n",
    "for (x1,y1,x2,y2), s in zip(boxes, scores):\n",
    "    draw.rectangle([x1,y1,x2,y2], outline=\"red\", width=2)\n",
    "    label = f\"car {s:.2f}\"\n",
    "    tw, th = font.getbbox(label)[2:]\n",
    "    draw.rectangle([x1, y1-th, x1+tw, y1], fill=\"red\")\n",
    "    draw.text((x1, y1-th), label, fill=\"white\", font=font)\n",
    "\n",
    "pil_img.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
