{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from pytorch_accelerated.callbacks import (\n",
    "    ModelEmaCallback,\n",
    "    ProgressBarCallback,\n",
    "    SaveBestModelCallback,\n",
    "    get_default_callbacks,\n",
    ")\n",
    "from pytorch_accelerated.schedulers import CosineLrScheduler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from yolov7 import create_yolov7_model\n",
    "from yolov7.dataset import (\n",
    "    Yolov7Dataset,\n",
    "    create_base_transforms,\n",
    "    create_yolov7_transforms,\n",
    "    yolov7_collate_fn,\n",
    ")\n",
    "from yolov7.evaluation import CalculateMeanAveragePrecisionCallback\n",
    "from yolov7.loss_factory import create_yolov7_loss\n",
    "from yolov7.mosaic import MosaicMixupDataset, create_post_mosaic_transform\n",
    "from yolov7.trainer import Yolov7Trainer, filter_eval_predictions\n",
    "from yolov7.utils import SaveBatchesCallback, Yolov7ModelEma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cars_df(annotations_file_path, images_path):\n",
    "    all_images = sorted(set([p.parts[-1] for p in images_path.iterdir()]))\n",
    "    image_id_to_image = {i: im for i, im in enumerate(all_images)}\n",
    "    image_to_image_id = {v: k for k, v, in image_id_to_image.items()}\n",
    "\n",
    "    annotations_df = pd.read_csv(annotations_file_path)\n",
    "    annotations_df.loc[:, \"class_name\"] = \"car\"\n",
    "    annotations_df.loc[:, \"has_annotation\"] = True\n",
    "\n",
    "    # add 100 empty images to the dataset\n",
    "    empty_images = sorted(set(all_images) - set(annotations_df.image.unique()))\n",
    "    non_annotated_df = pd.DataFrame(list(empty_images)[:100], columns=[\"image\"])\n",
    "    non_annotated_df.loc[:, \"has_annotation\"] = False\n",
    "    non_annotated_df.loc[:, \"class_name\"] = \"background\"\n",
    "\n",
    "    df = pd.concat((annotations_df, non_annotated_df))\n",
    "\n",
    "    class_id_to_label = dict(\n",
    "        enumerate(df.query(\"has_annotation == True\").class_name.unique())\n",
    "    )\n",
    "    class_label_to_id = {v: k for k, v in class_id_to_label.items()}\n",
    "\n",
    "    df[\"image_id\"] = df.image.map(image_to_image_id)\n",
    "    df[\"class_id\"] = df.class_name.map(class_label_to_id)\n",
    "\n",
    "    file_names = tuple(df.image.unique())\n",
    "    random.seed(42)\n",
    "    validation_files = set(random.sample(file_names, int(len(df) * 0.2)))\n",
    "    train_df = df[~df.image.isin(validation_files)]\n",
    "    valid_df = df[df.image.isin(validation_files)]\n",
    "\n",
    "    lookups = {\n",
    "        \"image_id_to_image\": image_id_to_image,\n",
    "        \"image_to_image_id\": image_to_image_id,\n",
    "        \"class_id_to_label\": class_id_to_label,\n",
    "        \"class_label_to_id\": class_label_to_id,\n",
    "    }\n",
    "    return train_df, valid_df, lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarsDatasetAdaptor(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir_path,\n",
    "        annotations_dataframe,\n",
    "        transforms=None,\n",
    "    ):\n",
    "        self.images_dir_path = Path(images_dir_path)\n",
    "        self.annotations_df = annotations_dataframe\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.image_idx_to_image_id = {\n",
    "            idx: image_id\n",
    "            for idx, image_id in enumerate(self.annotations_df.image_id.unique())\n",
    "        }\n",
    "        self.image_id_to_image_idx = {\n",
    "            v: k for k, v, in self.image_idx_to_image_id.items()\n",
    "        }\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_idx_to_image_id)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_idx_to_image_id[index]\n",
    "        image_info = self.annotations_df[self.annotations_df.image_id == image_id]\n",
    "        file_name = image_info.image.values[0]\n",
    "        assert image_id == image_info.image_id.values[0]\n",
    "\n",
    "        image = Image.open(self.images_dir_path / file_name).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "\n",
    "        image_hw = image.shape[:2]\n",
    "\n",
    "        if image_info.has_annotation.any():\n",
    "            xyxy_bboxes = image_info[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "            class_ids = image_info[\"class_id\"].values\n",
    "        else:\n",
    "            xyxy_bboxes = np.array([])\n",
    "            class_ids = np.array([])\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(\n",
    "                image=image, bboxes=xyxy_bboxes, labels=class_ids\n",
    "            )\n",
    "            image = transformed[\"image\"]\n",
    "            xyxy_bboxes = np.array(transformed[\"bboxes\"])\n",
    "            class_ids = np.array(transformed[\"labels\"])\n",
    "\n",
    "        return image, xyxy_bboxes, class_ids, image_id, image_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    data_path: str = '//content/drive/MyDrive/ExDark',\n",
    "    image_size: int = 640,\n",
    "    pretrained: bool = False,\n",
    "    num_epochs: int = 300,\n",
    "    batch_size: int = 8,\n",
    "):\n",
    "\n",
    "    # load data\n",
    "    data_path = Path(data_path)\n",
    "    images_path = data_path / \"training_images\"\n",
    "    annotations_file_path = data_path / \"annotations.csv\"\n",
    "    train_df, valid_df, lookups = load_cars_df(annotations_file_path, images_path)\n",
    "    num_classes = 1\n",
    "\n",
    "    print(train_df.head())\n",
    "    print(valid_df.head())\n",
    "\n",
    "\n",
    "    # create datasets\n",
    "    train_ds = CarsDatasetAdaptor(\n",
    "        images_path, train_df, transforms=create_base_transforms(image_size)\n",
    "    )\n",
    "    eval_ds = CarsDatasetAdaptor(images_path, valid_df)\n",
    "\n",
    "    mds = MosaicMixupDataset(\n",
    "        train_ds,\n",
    "        apply_mixup_probability=0.15,\n",
    "        post_mosaic_transforms=create_post_mosaic_transform(\n",
    "            output_height=image_size, output_width=image_size\n",
    "        ),\n",
    "    )\n",
    "    if pretrained:\n",
    "        # disable mosaic if finetuning\n",
    "        mds.disable()\n",
    "\n",
    "    train_yds = Yolov7Dataset(\n",
    "        mds,\n",
    "        create_yolov7_transforms(training=True, image_size=(image_size, image_size)),\n",
    "    )\n",
    "    eval_yds = Yolov7Dataset(\n",
    "        eval_ds,\n",
    "        create_yolov7_transforms(training=False, image_size=(image_size, image_size)),\n",
    "    )\n",
    "\n",
    "    # create model, loss function and optimizer\n",
    "    model = create_yolov7_model(\n",
    "        architecture=\"yolov7\", num_classes=num_classes, pretrained=pretrained\n",
    "    )\n",
    "    param_groups = model.get_parameter_groups()\n",
    "\n",
    "    loss_func = create_yolov7_loss(model, image_size=image_size)\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        param_groups[\"other_params\"], lr=0.01, momentum=0.937, nesterov=True\n",
    "    )\n",
    "\n",
    "    # create evaluation callback and trainer\n",
    "    calculate_map_callback = (\n",
    "        CalculateMeanAveragePrecisionCallback.create_from_targets_df(\n",
    "            targets_df=valid_df.query(\"has_annotation == True\")[\n",
    "                [\"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class_id\"]\n",
    "            ],\n",
    "            image_ids=set(valid_df.image_id.unique()),\n",
    "            iou_threshold=0.2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trainer = Yolov7Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_func,\n",
    "        filter_eval_predictions_fn=partial(\n",
    "            filter_eval_predictions, confidence_threshold=0.01, nms_threshold=0.3\n",
    "        ),\n",
    "        callbacks=[\n",
    "            calculate_map_callback,\n",
    "            ModelEmaCallback(\n",
    "                decay=0.9999,\n",
    "                model_ema=Yolov7ModelEma,\n",
    "                callbacks=[ProgressBarCallback, calculate_map_callback],\n",
    "            ),\n",
    "            SaveBestModelCallback(watch_metric=\"map\", greater_is_better=True),\n",
    "            SaveBatchesCallback(\"./batches\", num_images_per_batch=3),\n",
    "            *get_default_callbacks(progress_bar=True),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # calculate scaled weight decay and gradient accumulation steps\n",
    "    total_batch_size = (\n",
    "        batch_size * trainer._accelerator.num_processes\n",
    "    )  # batch size across all processes\n",
    "\n",
    "    nominal_batch_size = 64\n",
    "    num_accumulate_steps = max(round(nominal_batch_size / total_batch_size), 1)\n",
    "    base_weight_decay = 0.0005\n",
    "    scaled_weight_decay = (\n",
    "        base_weight_decay * total_batch_size * num_accumulate_steps / nominal_batch_size\n",
    "    )\n",
    "\n",
    "    optimizer.add_param_group(\n",
    "        {\"params\": param_groups[\"conv_weights\"], \"weight_decay\": scaled_weight_decay}\n",
    "    )\n",
    "\n",
    "    # run training\n",
    "    trainer.train(\n",
    "        num_epochs=num_epochs,\n",
    "        train_dataset=train_yds,\n",
    "        eval_dataset=eval_yds,\n",
    "        per_device_batch_size=batch_size,\n",
    "        create_scheduler_fn=CosineLrScheduler.create_scheduler_fn(\n",
    "            num_warmup_epochs=5,\n",
    "            num_cooldown_epochs=5,\n",
    "            k_decay=2,\n",
    "        ),\n",
    "        collate_fn=yolov7_collate_fn,\n",
    "        gradient_accumulation_steps=num_accumulate_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
